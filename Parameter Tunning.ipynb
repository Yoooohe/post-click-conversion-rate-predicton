{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import operator\n",
    "from collections import Counter\n",
    "\n",
    "import xgboost as xgb\n",
    "#import lightgbm as lgb\n",
    "from sklearn.metrics import log_loss\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from contextlib import contextmanager\n",
    "@contextmanager\n",
    "def timer(name):\n",
    "    start_time = time.time()\n",
    "    yield\n",
    "    print(f'[{name} done in {time.time() - start_time:.2f} s]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys([17, 18, 19, 20, 21, 22, 23, 24])\n",
      "dict_keys([25, 24])\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv('data/processed_train.csv')\n",
    "test = pd.read_csv('data/processed_test.csv')\n",
    "print(Counter(train['day']).keys())\n",
    "print(Counter(test['day']).keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort data according to day and time\n",
    "train = train.sort_values(by = ['day','time']).reset_index().iloc[:, 1:]\n",
    "# convert hour to time slot\n",
    "# is_midnight: 0, is_morning: 1, is_afternoon: 2, is_night: 3\n",
    "def f(x):\n",
    "    if x <= 7:\n",
    "        return 0\n",
    "    elif x > 7 and x <= 13:\n",
    "        return 1\n",
    "    elif x > 13 and x <= 19:\n",
    "        return 2\n",
    "    else:\n",
    "        return 3\n",
    "train['hour'] = train['hour'].apply(lambda x: f(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete some features\n",
    "# check importance of features\n",
    "exclude_features = ['instance_id','context_id', 'context_timestamp', 'is_trade','datetime', 'day', 'time']\n",
    "df_train = train[(train['day'] >= 17) & (train['day'] <= 22)]\n",
    "df_val = train[(train['day'] >= 23) & (train['day'] <= 24)]\n",
    "y_train = df_train['is_trade']\n",
    "x_train = df_train.drop(exclude_features, axis = 1)\n",
    "y_val = df_val['is_trade']\n",
    "x_val = df_val.drop(exclude_features, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logloss(act, pred):\n",
    "    epsilon = 1e-15\n",
    "    pred = np.maximum(epsilon, pred)\n",
    "    pred = np.minimum(1-epsilon, pred)\n",
    "    ll = sum(act*np.log(pred) + (1-act)*np.log(1-pred))\n",
    "    ll = ll * -1.0/len(act)\n",
    "    return ll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare for training\n",
    "params = {'max_depth':8, # 3-10\n",
    "          'eta':0.05, # 0.01-0.2 analogous to learning rate\n",
    "          'subsample':0.7, #0.5-1 denote the fraction of observations to be randomly samples for each tree.\n",
    "          'colsample_bytree':0.5, #0.5-1 denote the fraction of columns to be randomly samples for each tree.\n",
    "          'min_child_weight':10,\n",
    "          \n",
    "          'seed':123,\n",
    "          'nthread':25,\n",
    "          'eval_metric':'logloss', #rmse, logloss, auc\n",
    "          'objective':'binary:logistic',\n",
    "          'silent':1\n",
    "          \n",
    "          # handle imbalanced dataset\n",
    "          #'scale_pos_weight':0.5\n",
    "          # 'max_delta_step': 1\n",
    "          }\n",
    "num_boost_round = 500\n",
    "\n",
    "dtrain = xgb.DMatrix(x_train, y_train)\n",
    "dvalid = xgb.DMatrix(x_val, y_val)\n",
    "watchlist = [(dtrain, 'train'), (dvalid, 'eval')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-logloss:0.648111\teval-logloss:0.647771\n",
      "Multiple eval metrics have been passed: 'eval-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until eval-logloss hasn't improved in 200 rounds.\n",
      "[50]\ttrain-logloss:0.108223\teval-logloss:0.100862\n",
      "[100]\ttrain-logloss:0.084422\teval-logloss:0.078325\n",
      "[150]\ttrain-logloss:0.080109\teval-logloss:0.076948\n",
      "[200]\ttrain-logloss:0.077294\teval-logloss:0.076755\n",
      "[250]\ttrain-logloss:0.075364\teval-logloss:0.076745\n",
      "[300]\ttrain-logloss:0.073384\teval-logloss:0.076756\n",
      "[350]\ttrain-logloss:0.071698\teval-logloss:0.0768\n",
      "[400]\ttrain-logloss:0.069882\teval-logloss:0.076883\n",
      "Stopping. Best iteration:\n",
      "[224]\ttrain-logloss:0.076325\teval-logloss:0.076727\n",
      "\n",
      "[Train XBOOST done in 839.52 s]\n"
     ]
    }
   ],
   "source": [
    "with timer('Train XBOOST'):\n",
    "    gbm = xgb.train(params, dtrain, num_boost_round, evals=watchlist, \n",
    "                    early_stopping_rounds=200, verbose_eval=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------- -------------\n",
      "max_depth =  9\n",
      "min_child_weight =  14\n",
      "Model 0 best logloss = 0.076642\n",
      "Best so far!\n",
      "Minimal logloss 0.076642\n",
      "[One round: done in 502.60 s]\n"
     ]
    }
   ],
   "source": [
    "# Paramter Tunning:\n",
    "# According to previous training, we choose num_boost_round = 224\n",
    "\n",
    "# Tune max_depth and min_child_weight\n",
    "# max_depth: 3-10   tried (4,10,1)\n",
    "# min_child_weight: 1-10  tried (2,18,2)\n",
    "\n",
    "max_depths = range(9,10,1)\n",
    "min_child_weights = range(14,15,1)\n",
    "\n",
    "iter_ = 0\n",
    "best_iter = 0\n",
    "best_logloss = 0.07672\n",
    "best_model = None\n",
    "\n",
    "for max_depth in max_depths:\n",
    "    for min_child_weight in min_child_weights:\n",
    "        with timer('One round:'):\n",
    "            print('----------- -------------')\n",
    "            print('max_depth = ',max_depth)\n",
    "            print('min_child_weight = ',min_child_weight)\n",
    "            params1 = dict(params,min_child_weight = min_child_weight,max_depth = max_depth)\n",
    "            model = xgb.train(params1,dtrain,num_boost_round = 224,evals = watchlist, \n",
    "                              early_stopping_rounds=200, verbose_eval = False)\n",
    "            print('Model %d best logloss = %.6f'%(iter_,model.best_score))\n",
    "            \n",
    "            if model.best_score < best_logloss:\n",
    "                best_logloss = model.best_score\n",
    "                best_iter = iter_\n",
    "                best_model = model\n",
    "                print('Best so far!')\n",
    "                print('Minimal logloss', best_logloss)\n",
    "            \n",
    "            iter_ += 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------- -------------\n",
      "gamma =  0.1\n",
      "Model 0 best logloss = 0.076642\n",
      "[One round: done in 502.83 s]\n",
      "----------- -------------\n",
      "gamma =  0.2\n",
      "Model 1 best logloss = 0.076642\n",
      "[One round: done in 520.05 s]\n",
      "----------- -------------\n",
      "gamma =  0.3\n",
      "Model 2 best logloss = 0.076642\n",
      "[One round: done in 492.09 s]\n",
      "----------- -------------\n",
      "gamma =  0.4\n",
      "Model 3 best logloss = 0.076642\n",
      "[One round: done in 508.93 s]\n",
      "----------- -------------\n",
      "gamma =  0.5\n",
      "Model 4 best logloss = 0.076642\n",
      "[One round: done in 493.35 s]\n"
     ]
    }
   ],
   "source": [
    "# Tune scale_pos_weight: default is 1\n",
    "# We tried 0.5-0.9\n",
    "# the best_logloss is still the default one\n",
    "\n",
    "# Tune gamma: default is 0, larger gamma, more conservative\n",
    "# 'gamma':[i/10.0 for i in range(0,5)]\n",
    "# the best_logloss is still the default one\n",
    "\n",
    "params1 = dict(params,max_depth = 9, min_child_weight = 14)\n",
    "gammas = [i/10.0 for i in range(1,6)]\n",
    "\n",
    "iter_ = 0\n",
    "best_iter = 0\n",
    "best_logloss = 0.076642\n",
    "best_model = None\n",
    "\n",
    "for gamma in gammas:\n",
    "    with timer('One round:'):\n",
    "            print('----------- -------------')\n",
    "            print('gamma = ',gamma)\n",
    "            params2 = dict(params1,gamma = gamma)\n",
    "            model = xgb.train(params1,dtrain,num_boost_round = 224,evals = watchlist, \n",
    "                              early_stopping_rounds=200, verbose_eval = False)\n",
    "            print('Model %d best logloss = %.6f'%(iter_,model.best_score))\n",
    "            \n",
    "            if model.best_score < best_logloss:\n",
    "                best_logloss = model.best_score\n",
    "                best_iter = iter_\n",
    "                best_model = model\n",
    "                print('Best so far!')\n",
    "                print('Minimal logloss', best_logloss)\n",
    "            \n",
    "            iter_ += 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------- -------------\n",
      "subsample =  0.5\n",
      "colsample =  0.5\n",
      "Model 0 best logloss = 0.076845\n",
      "[One round: done in 483.47 s]\n",
      "----------- -------------\n",
      "subsample =  0.5\n",
      "colsample =  0.6\n",
      "Model 1 best logloss = 0.076845\n",
      "[One round: done in 483.78 s]\n",
      "----------- -------------\n",
      "subsample =  0.5\n",
      "colsample =  0.7\n",
      "Model 2 best logloss = 0.076845\n",
      "[One round: done in 527.93 s]\n",
      "----------- -------------\n",
      "subsample =  0.5\n",
      "colsample =  0.8\n",
      "Model 3 best logloss = 0.076845\n",
      "[One round: done in 484.71 s]\n",
      "----------- -------------\n",
      "subsample =  0.5\n",
      "colsample =  0.9\n",
      "Model 4 best logloss = 0.076845\n",
      "[One round: done in 515.17 s]\n",
      "----------- -------------\n",
      "subsample =  0.6\n",
      "colsample =  0.5\n",
      "Model 5 best logloss = 0.076805\n",
      "[One round: done in 524.16 s]\n",
      "----------- -------------\n",
      "subsample =  0.6\n",
      "colsample =  0.6\n",
      "Model 6 best logloss = 0.076805\n",
      "[One round: done in 498.08 s]\n",
      "----------- -------------\n",
      "subsample =  0.6\n",
      "colsample =  0.7\n",
      "Model 7 best logloss = 0.076805\n",
      "[One round: done in 509.16 s]\n",
      "----------- -------------\n",
      "subsample =  0.6\n",
      "colsample =  0.8\n",
      "Model 8 best logloss = 0.076805\n",
      "[One round: done in 514.60 s]\n",
      "----------- -------------\n",
      "subsample =  0.6\n",
      "colsample =  0.9\n",
      "Model 9 best logloss = 0.076805\n",
      "[One round: done in 511.61 s]\n",
      "----------- -------------\n",
      "subsample =  0.7\n",
      "colsample =  0.5\n",
      "Model 10 best logloss = 0.076642\n",
      "[One round: done in 501.83 s]\n",
      "----------- -------------\n",
      "subsample =  0.7\n",
      "colsample =  0.6\n",
      "Model 11 best logloss = 0.076642\n",
      "[One round: done in 511.30 s]\n",
      "----------- -------------\n",
      "subsample =  0.7\n",
      "colsample =  0.7\n",
      "Model 12 best logloss = 0.076642\n",
      "[One round: done in 514.98 s]\n",
      "----------- -------------\n",
      "subsample =  0.7\n",
      "colsample =  0.8\n",
      "Model 13 best logloss = 0.076642\n",
      "[One round: done in 506.93 s]\n",
      "----------- -------------\n",
      "subsample =  0.7\n",
      "colsample =  0.9\n",
      "Model 14 best logloss = 0.076642\n",
      "[One round: done in 517.73 s]\n",
      "----------- -------------\n",
      "subsample =  0.8\n",
      "colsample =  0.5\n",
      "Model 15 best logloss = 0.076573\n",
      "Best so far!\n",
      "Minimal logloss 0.076573\n",
      "[One round: done in 486.58 s]\n",
      "----------- -------------\n",
      "subsample =  0.8\n",
      "colsample =  0.6\n",
      "Model 16 best logloss = 0.076573\n",
      "[One round: done in 486.93 s]\n",
      "----------- -------------\n",
      "subsample =  0.8\n",
      "colsample =  0.7\n",
      "Model 17 best logloss = 0.076573\n",
      "[One round: done in 499.73 s]\n",
      "----------- -------------\n",
      "subsample =  0.8\n",
      "colsample =  0.8\n",
      "Model 18 best logloss = 0.076573\n",
      "[One round: done in 503.45 s]\n",
      "----------- -------------\n",
      "subsample =  0.8\n",
      "colsample =  0.9\n",
      "Model 19 best logloss = 0.076573\n",
      "[One round: done in 505.07 s]\n",
      "----------- -------------\n",
      "subsample =  0.9\n",
      "colsample =  0.5\n",
      "Model 20 best logloss = 0.076611\n",
      "[One round: done in 504.59 s]\n",
      "----------- -------------\n",
      "subsample =  0.9\n",
      "colsample =  0.6\n",
      "Model 21 best logloss = 0.076611\n",
      "[One round: done in 504.49 s]\n",
      "----------- -------------\n",
      "subsample =  0.9\n",
      "colsample =  0.7\n",
      "Model 22 best logloss = 0.076611\n",
      "[One round: done in 483.27 s]\n",
      "----------- -------------\n",
      "subsample =  0.9\n",
      "colsample =  0.8\n",
      "Model 23 best logloss = 0.076611\n",
      "[One round: done in 499.96 s]\n",
      "----------- -------------\n",
      "subsample =  0.9\n",
      "colsample =  0.9\n",
      "Model 24 best logloss = 0.076611\n",
      "[One round: done in 495.82 s]\n"
     ]
    }
   ],
   "source": [
    "# Tune subsample and colsample_bytree\n",
    "# 'subsample':[i/10.0 for i in range(6,10)],\n",
    "# 'colsample_bytree':[i/10.0 for i in range(6,10)]\n",
    "\n",
    "# subsample =  0.8\n",
    "# colsample =  0.5\n",
    "# best_logloss = 0.076573\n",
    "\n",
    "params1 = dict(params,max_depth = 9, min_child_weight = 14)\n",
    "\n",
    "subsamples = [i/10.0 for i in range(5,10)]\n",
    "colsample_bytrees = [i/10.0 for i in range(5,10)]\n",
    "\n",
    "iter_ = 0\n",
    "best_iter = 0\n",
    "best_logloss = 0.076642\n",
    "best_model = None\n",
    "\n",
    "for subsample in subsamples:\n",
    "    for colsample_bytree in colsample_bytrees:\n",
    "        with timer('One round:'):\n",
    "            print('----------- -------------')\n",
    "            print('subsample = ',subsample)\n",
    "            print('colsample = ',colsample_bytree)\n",
    "            params1 = dict(params1,subsample = subsample,colsample = colsample_bytree)\n",
    "            model = xgb.train(params1,dtrain,num_boost_round = 224,evals = watchlist, \n",
    "                              early_stopping_rounds=200, verbose_eval = False)\n",
    "            print('Model %d best logloss = %.6f'%(iter_,model.best_score))\n",
    "            \n",
    "            if model.best_score < best_logloss:\n",
    "                best_logloss = model.best_score\n",
    "                best_iter = iter_\n",
    "                best_model = model\n",
    "                print('Best so far!')\n",
    "                print('Minimal logloss', best_logloss)\n",
    "            \n",
    "            iter_ += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------- -------------\n",
      "lambda =  0.5\n",
      "Model 0 best logloss = 0.076546\n",
      "Best so far!\n",
      "Minimal logloss 0.076546\n",
      "[One round: done in 514.38 s]\n"
     ]
    }
   ],
   "source": [
    "# Tuning Regularization Parameters\n",
    "# lambda: [1e-5, 1e-2, 0.1, 1, 100]  L2 (similar to ridge regression) default = 1\n",
    "# alpha:  L1 (similar to lasso regression)  default = 0\n",
    "params2 = dict(params1,subsample = 0.8, colsample_bytree = 0.5)\n",
    "\n",
    "#lambdas = [1e-5, 1e-2, 0.1, 1, 100]\n",
    "#lambdas = [0.5, 0.8, 1.5, 1.8, 2.5]\n",
    "#lambdas = [0.51, 0.52, 0.53, 0.54, 0.55]\n",
    "lambdas = [0.5]\n",
    "\n",
    "iter_ = 0\n",
    "best_iter = 0\n",
    "best_logloss = 0.076573\n",
    "best_model = None\n",
    "\n",
    "for la in lambdas:\n",
    "    with timer('One round:'):\n",
    "            print('----------- -------------')\n",
    "            print('lambda = ',la)\n",
    "            params2['lambda'] = la\n",
    "            model = xgb.train(params2,dtrain,num_boost_round = 224,evals = watchlist, \n",
    "                              early_stopping_rounds=200, verbose_eval = False)\n",
    "            print('Model %d best logloss = %.6f'%(iter_,model.best_score))\n",
    "            \n",
    "            if model.best_score < best_logloss:\n",
    "                best_logloss = model.best_score\n",
    "                best_iter = iter_\n",
    "                best_model = model\n",
    "                print('Best so far!')\n",
    "                print('Minimal logloss', best_logloss)\n",
    "            \n",
    "            iter_ += 1\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can get only optimize the model in a small extent by parameter tunning. \n",
    "The best logloss of this model is 0.076546\n",
    "If we want to greatly improve the model, we need to reply on other techniques, such as feature engineering, ensemble of model, stacking and etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
